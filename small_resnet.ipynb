{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import os\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Import the library to mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","FOLDERNAME = 'DL project/fma'\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","%cd /content/drive/My\\ Drive/$FOLDERNAME/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmXWCFGGbrTC","executionInfo":{"status":"ok","timestamp":1733312994473,"user_tz":480,"elapsed":27984,"user":{"displayName":"sub pewd","userId":"05464962512905770541"}},"outputId":"484734ff-2fc3-4fab-c27f-1ca7dd9cb419"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1Gzbs2MQ8ttHuTOpxDaZoGkbdHOw1ukQO/DL project/fma\n"]}]},{"cell_type":"code","source":["# import os\n","# import numpy as np\n","\n","# dataset_dir = \"data/spec_small2/\"  # Update with your dataset directory\n","\n","# def check_npy_files(dataset_dir):\n","#     for class_name in sorted(os.listdir(dataset_dir)):\n","#         class_path = os.path.join(dataset_dir, class_name)\n","#         if not os.path.isdir(class_path):\n","#             continue\n","#         for file_name in os.listdir(class_path):\n","#             if file_name.endswith(\".npy\"):\n","#                 file_path = os.path.join(class_path, file_name)\n","#                 try:\n","#                     data = np.load(file_path)  # Try loading the file\n","#                     if data.size == 0:  # Check if the loaded data is empty\n","#                         print(f\"WARNING: Empty .npy file found: {file_path}\")\n","#                 except EOFError:\n","#                     print(f\"WARNING: Corrupted .npy file found: {file_path}\")\n","#                 except Exception as e:\n","#                     print(f\"WARNING: Error loading .npy file: {file_path}, Error: {e}\")\n","\n","# # Call the function to check your files\n","# check_npy_files(dataset_dir + \"train\")\n","# check_npy_files(dataset_dir + \"val\")\n","\n","# i = 0\n","# f = set()\n","# for subdir, dirs, files in os.walk('data/spec_small2/'):\n","#     for file in files:\n","#         i += 1\n","# print(i)\n","        # if '(' in file:\n","        #     file_path = os.path.join(subdir, file)\n","        #     print(file)\n","        #     os.remove(file_path)\n","        # num = int(file[:-4])\n","        # if num >= 139775 and num <= 141566:\n","        #     file_path = os.path.join(subdir, file)\n","        #     if os.path.exists(file_path):\n","        #         # os.remove(file_path)\n","        #         print(num, end = \" \")\n","\n","\n","    #   npy = np.load(file_path)\n","\n","    #   if npy.shape != (10000,):\n","    #     print(npy.shape)\n","    #     os.remove(file_path)\n","    #   i+= 1\n","\n","    #   if i %100 == 0:\n","    #     print(i , file)"],"metadata":{"id":"tZU99BUsdW8L","executionInfo":{"status":"ok","timestamp":1733312822519,"user_tz":480,"elapsed":69464,"user":{"displayName":"sub pewd","userId":"05464962512905770541"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import math\n","from tensorflow import keras\n","from tensorflow.keras import layers, regularizers\n","\n","NUM_CLASSES = 8\n","\n","kaiming_normal = keras.initializers.VarianceScaling(scale=2.0, mode='fan_out', distribution='untruncated_normal')\n","\n","def conv3x3(x, out_planes, stride=1, name=None):\n","    x = layers.ZeroPadding2D(padding=1, name=f'{name}_pad')(x)\n","    return layers.Conv2D(filters=out_planes, kernel_size=3, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=name, kernel_regularizer=regularizers.L2(0.01),)(x)\n","\n","def basic_block(x, planes, stride=1, downsample=None, name=None):\n","    identity = x\n","\n","    out = conv3x3(x, planes, stride=stride, name=f'{name}.conv1')\n","    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn1')(out)\n","    out = layers.ReLU(name=f'{name}.relu1')(out)\n","\n","    out = conv3x3(out, planes, name=f'{name}.conv2')\n","    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn2')(out)\n","\n","    if downsample is not None:\n","        for layer in downsample:\n","            identity = layer(identity)\n","\n","    out = layers.Add(name=f'{name}.add')([identity, out])\n","    out = layers.ReLU(name=f'{name}.relu2')(out)\n","\n","    return out\n","\n","def make_layer(x, planes, blocks, stride=1, name=None):\n","    downsample = None\n","    inplanes = x.shape[2]\n","    if stride != 1 or inplanes != planes:\n","        downsample = [\n","            layers.Conv2D(filters=planes, kernel_size=1, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=f'{name}.0.downsample.0'),\n","            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.0.downsample.1'),\n","        ]\n","\n","    x = basic_block(x, planes, stride, downsample, name=f'{name}.0')\n","    for i in range(1, blocks):\n","        x = basic_block(x, planes, name=f'{name}.{i}')\n","\n","    return x\n","\n","def resnet(x, blocks_per_layer, num_classes=1000):\n","    x = layers.Reshape((x.shape[-2],x.shape[-1], 1))(x)\n","    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn0')(x)\n","    # x = layers.ZeroPadding2D(padding=3, name='conv1_pad')(x)\n","    x = layers.Conv2D(filters=64, kernel_size=7, strides=2, use_bias=False, kernel_initializer=kaiming_normal, name='conv1')(x)\n","    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n","    x = layers.ReLU(name='relu1')(x)\n","    # x = layers.ZeroPadding2D(padding=1, name='maxpool_pad')(x)\n","    x = layers.MaxPool2D(pool_size=3, strides=2, name='maxpool')(x)\n","\n","    x = make_layer(x, 64, blocks_per_layer[0], name='layer1')\n","    x = make_layer(x, 128, blocks_per_layer[1], stride=2, name='layer2')\n","    x = make_layer(x, 256, blocks_per_layer[2], stride=2, name='layer3')\n","    x = make_layer(x, 512, blocks_per_layer[3], stride=2, name='layer4')\n","\n","    x = layers.GlobalAveragePooling2D(name='avgpool')(x)\n","    initializer = keras.initializers.RandomUniform(-1.0 / math.sqrt(512), 1.0 / math.sqrt(512))\n","    x = layers.Dense(units=num_classes, kernel_initializer=initializer, bias_initializer=initializer, name='fc')(x)\n","    x = layers.Activation('softmax')(x)\n","\n","    return x\n","\n","def resnet18(x, **kwargs):\n","    return resnet(x,  [3, 4, 6, 3], **kwargs)\n","\n","inputs = keras.Input(shape=(128, 12))\n","# inputs = keras.Input(shape=(59953,))\n","outputs = resnet18(inputs, num_classes=NUM_CLASSES)\n","\n","model = keras.Model(inputs, outputs)\n","\n","\n","\n","# model = tf.keras.models.Sequential([\n","#     layers.Reshape((128, 12, 1)),\n","#     tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 12, 1)), # Convolutional layer\n","#     tf.keras.layers.BatchNormalization(), # Batch normalization\n","#     tf.keras.layers.MaxPooling2D((2, 2)), # Max pooling\n","#     tf.keras.layers.Conv2D(64, (3, 3), activation='relu'), # Another convolutional layer\n","#     tf.keras.layers.BatchNormalization(), # Batch normalization\n","#     tf.keras.layers.MaxPooling2D((2, 2)), # Max pooling\n","#     tf.keras.layers.Flatten(), # Flatten the output for the dense layers\n","#     tf.keras.layers.Dense(8, activation='softmax') # Output layer with 10 units (e.g., for 10 classes)\n","# ])\n","\n"],"metadata":{"id":"Fc3y1Wp7gq8P","executionInfo":{"status":"ok","timestamp":1733315230596,"user_tz":480,"elapsed":593,"user":{"displayName":"sub pewd","userId":"05464962512905770541"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g02vMCcfbKBD","executionInfo":{"status":"ok","timestamp":1733316106403,"user_tz":480,"elapsed":1897,"user":{"displayName":"sub pewd","userId":"05464962512905770541"}},"outputId":"edb35df7-63d5-4a9b-d744-88f423eeaaa3"},"outputs":[{"output_type":"stream","name":"stdout","text":["6397\n","6397\n","800\n","800\n","800\n","800\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","\n","\n","dataset_dir = \"data/spec_small2/\"\n","\n","# Function to load a single .npy file and assign its label\n","def load_npy_file(file_path, label):\n","    # Read the file and decode its path\n","    npy = tf.numpy_function(lambda path: np.load(path).astype(np.float32), [file_path], tf.float32)\n","    npy.set_shape([128,12])  # Set shape (update according to your spectrogram's dimensions)\n","\n","    return npy, label\n","\n","\n","# Function to create a dataset for all files\n","def create_dataset(dataset_dir):\n","    # List all files and infer labels from folder names\n","    all_files = []\n","    all_labels = []\n","    for class_name in sorted(os.listdir(dataset_dir)):\n","        class_path = os.path.join(dataset_dir, class_name)\n","        if not os.path.isdir(class_path):\n","            continue\n","        label = ([int(digit) for digit in class_name])  # Convert folder name to integer label\n","        files = [os.path.join(class_path, f) for f in os.listdir(class_path) if f.endswith(\".npy\")]\n","        all_files.extend(files)\n","        all_labels.extend([label] * len(files))\n","\n","    print(len(all_labels))\n","    print(len(all_files))\n","\n","\n","\n","    # Create a dataset from the files and labels\n","    file_paths = tf.constant(all_files)\n","    labels = tf.constant(all_labels, dtype=tf.int32)\n","    num_classes = 8  # Determine the number of classes\n","    # labels = tf.one_hot(labels, depth=num_classes)  # Apply one-hot encoding\n","    # print(labels)\n","\n","    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n","    dataset = dataset.shuffle(len(all_files))  # Shuffle dataset\n","    dataset = dataset.map(load_npy_file, num_parallel_calls=tf.data.AUTOTUNE)  # Load files\n","    batch_size = 64\n","    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return dataset, all_labels\n","\n","\n","# Create the train dataset\n","train_dataset, _ = create_dataset(dataset_dir+\"train\")\n","val_dataset, _ = create_dataset(dataset_dir+\"val\")\n","test_dataset, test_labels = create_dataset(dataset_dir+\"test\")\n","\n","\n","# Inspect a sample\n","# for spectrogram, label in train_dataset.take(1):\n","#     print(\"Spectrogram shape:\", spectrogram.shape)\n","#     print(\"Label:\", label.shape)\n","#     num_classes = label.shape[1]\n"]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","new_optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n","model.compile(\n","    optimizer=new_optimizer ,\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","checkpoint = ModelCheckpoint(\n","    filepath='best_small_specresnet_model30.keras',  # Filepath to save the model\n","    monitor='val_loss',       # Metric to monitor (e.g., 'val_loss', 'val_accuracy')\n","    save_best_only=True,      # Save only the best model\n","    save_weights_only=False,  # Save the entire model (not just weights)\n","    mode='min',               # Save when the monitored metric decreases ('min') or increases ('max')\n","    verbose=1                 # Print a message when saving\n",")\n","\n","\n","\n","\n","history = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=30,\n","    verbose=1,\n","    callbacks=[checkpoint]\n","    # callbacks=[PrintEveryFewBatchesCallback(interval=1), checkpoint]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TctUxBoBj93t","outputId":"c83621b5-6820-436b-80c5-3b3a9bf48b1c","executionInfo":{"status":"error","timestamp":1733317000259,"user_tz":480,"elapsed":548083,"user":{"displayName":"sub pewd","userId":"05464962512905770541"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.6320 - loss: 85.1470\n","Epoch 1: val_loss improved from inf to 83.38602, saving model to best_small_specresnet_model30.keras\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 388ms/step - accuracy: 0.6319 - loss: 85.1388 - val_accuracy: 0.2962 - val_loss: 83.3860\n","Epoch 2/30\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.6434 - loss: 81.7878\n","Epoch 2: val_loss improved from 83.38602 to 80.32890, saving model to best_small_specresnet_model30.keras\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 232ms/step - accuracy: 0.6435 - loss: 81.7802 - val_accuracy: 0.2837 - val_loss: 80.3289\n","Epoch 3/30\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.6855 - loss: 78.6690\n","Epoch 3: val_loss improved from 80.32890 to 77.50587, saving model to best_small_specresnet_model30.keras\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 230ms/step - accuracy: 0.6854 - loss: 78.6620 - val_accuracy: 0.3000 - val_loss: 77.5059\n","Epoch 4/30\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7214 - loss: 75.7430\n","Epoch 4: val_loss improved from 77.50587 to 74.92976, saving model to best_small_specresnet_model30.keras\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 237ms/step - accuracy: 0.7213 - loss: 75.7368 - val_accuracy: 0.2900 - val_loss: 74.9298\n","Epoch 5/30\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.7302 - loss: 73.1121\n","Epoch 5: val_loss improved from 74.92976 to 72.42171, saving model to best_small_specresnet_model30.keras\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 281ms/step - accuracy: 0.7302 - loss: 73.1058 - val_accuracy: 0.3063 - val_loss: 72.4217\n","Epoch 6/30\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.7524 - loss: 70.5921\n","Epoch 6: val_loss improved from 72.42171 to 70.20588, saving model to best_small_specresnet_model30.keras\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 245ms/step - accuracy: 0.7523 - loss: 70.5865 - val_accuracy: 0.2900 - val_loss: 70.2059\n","Epoch 7/30\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.7803 - loss: 68.2297\n","Epoch 7: val_loss improved from 70.20588 to 68.05268, saving model to best_small_specresnet_model30.keras\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 255ms/step - accuracy: 0.7803 - loss: 68.2243 - val_accuracy: 0.2862 - val_loss: 68.0527\n","Epoch 8/30\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.8055 - loss: 66.0200\n","Epoch 8: val_loss improved from 68.05268 to 66.07795, saving model to best_small_specresnet_model30.keras\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 239ms/step - accuracy: 0.8055 - loss: 66.0150 - val_accuracy: 0.2962 - val_loss: 66.0779\n","Epoch 9/30\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.8315 - loss: 63.9522\n","Epoch 9: val_loss improved from 66.07795 to 64.18552, saving model to best_small_specresnet_model30.keras\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 239ms/step - accuracy: 0.8314 - loss: 63.9477 - val_accuracy: 0.2812 - val_loss: 64.1855\n","Epoch 10/30\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.8299 - loss: 62.0303\n","Epoch 10: val_loss improved from 64.18552 to 62.41707, saving model to best_small_specresnet_model30.keras\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 283ms/step - accuracy: 0.8298 - loss: 62.0259 - val_accuracy: 0.2875 - val_loss: 62.4171\n","Epoch 11/30\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.8247 - loss: 60.2749\n","Epoch 11: val_loss improved from 62.41707 to 60.78093, saving model to best_small_specresnet_model30.keras\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 284ms/step - accuracy: 0.8248 - loss: 60.2704 - val_accuracy: 0.2825 - val_loss: 60.7809\n","Epoch 12/30\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.8446 - loss: 58.5287\n","Epoch 12: val_loss improved from 60.78093 to 59.21487, saving model to best_small_specresnet_model30.keras\n","\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 285ms/step - accuracy: 0.8447 - loss: 58.5246 - val_accuracy: 0.2713 - val_loss: 59.2149\n","Epoch 13/30\n","\u001b[1m 17/100\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 204ms/step - accuracy: 0.8683 - loss: 57.1877"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-2153e80ee951>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["model = tf.keras.models.load_model('final_models/best_small_specresnet_model.keras')\n","raw_pred = model.predict(test_dataset)\n","pred_labels = np.argmax(raw_pred, axis=1)\n","true_labels = np.argmax(test_labels, axis=1)\n","\n","print(np.sum(pred_labels == true_labels)/800)\n","correct = [0]*8\n","for i in range(800):\n","    if pred_labels[i] == true_labels[i]:\n","        correct[true_labels[i]] +=1\n","\n","\n","print([c/100 for c in correct])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w6z8AfNNr3ER","executionInfo":{"status":"ok","timestamp":1733317108209,"user_tz":480,"elapsed":9489,"user":{"displayName":"sub pewd","userId":"05464962512905770541"}},"outputId":"a1fe1d36-7d27-450f-80ff-a73639ea206b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 309ms/step\n","0.14\n","[0.09, 0.17, 0.13, 0.2, 0.03, 0.2, 0.1, 0.2]\n"]}]}]}