{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import os\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Import the library to mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","FOLDERNAME = 'DL project/fma'\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","%cd /content/drive/My\\ Drive/$FOLDERNAME/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jmXWCFGGbrTC","executionInfo":{"status":"ok","timestamp":1733258732817,"user_tz":480,"elapsed":959,"user":{"displayName":"Frank Wu","userId":"09777963439135390486"}},"outputId":"d02aaf91-e630-4f1c-a49f-7e95328a4dc7"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1Gzbs2MQ8ttHuTOpxDaZoGkbdHOw1ukQO/DL project/fma\n"]}]},{"cell_type":"code","source":["import math\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","NUM_CLASSES = 8\n","\n","kaiming_normal = keras.initializers.VarianceScaling(scale=2.0, mode='fan_out', distribution='untruncated_normal')\n","\n","def conv3x3(x, out_planes, stride=1, name=None):\n","    x = layers.ZeroPadding1D(padding=1, name=f'{name}_pad')(x)\n","    return layers.Conv1D(filters=out_planes, kernel_size=3, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=name)(x)\n","\n","def basic_block(x, planes, stride=1, downsample=None, name=None):\n","    identity = x\n","\n","    out = conv3x3(x, planes, stride=stride, name=f'{name}.conv1')\n","    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn1')(out)\n","    out = layers.ReLU(name=f'{name}.relu1')(out)\n","\n","    out = conv3x3(out, planes, name=f'{name}.conv2')\n","    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn2')(out)\n","\n","    if downsample is not None:\n","        for layer in downsample:\n","            identity = layer(identity)\n","\n","    out = layers.Add(name=f'{name}.add')([identity, out])\n","    out = layers.ReLU(name=f'{name}.relu2')(out)\n","\n","    return out\n","\n","def make_layer(x, planes, blocks, stride=1, name=None):\n","    downsample = None\n","    inplanes = x.shape[2]\n","    if stride != 1 or inplanes != planes:\n","        downsample = [\n","            layers.Conv1D(filters=planes, kernel_size=1, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=f'{name}.0.downsample.0'),\n","            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.0.downsample.1'),\n","        ]\n","\n","    x = basic_block(x, planes, stride, downsample, name=f'{name}.0')\n","    for i in range(1, blocks):\n","        x = basic_block(x, planes, name=f'{name}.{i}')\n","\n","    return x\n","\n","def resnet(x, blocks_per_layer, rnn_n_layers, rnn_type, bidirectional, num_classes=1000):\n","    x = layers.Reshape((x.shape[-1], 1))(x)\n","    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn0')(x)\n","    x = layers.ZeroPadding1D(padding=3, name='conv1_pad')(x)\n","    x = layers.Conv1D(filters=64, kernel_size=7, strides=2, use_bias=False, kernel_initializer=kaiming_normal, name='conv1')(x)\n","    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n","    x = layers.ReLU(name='relu1')(x)\n","    x = layers.ZeroPadding1D(padding=1, name='maxpool_pad')(x)\n","    x = layers.MaxPool1D(pool_size=3, strides=2, name='maxpool')(x)\n","\n","    x = make_layer(x, 64, blocks_per_layer[0], name='layer1')\n","    # x = make_layer(x, 64, blocks_per_layer[0], stride=3, name='layer11')\n","    x = make_layer(x, 128, blocks_per_layer[1], stride=3, name='layer2')\n","    x = make_layer(x, 256, blocks_per_layer[2], stride=3, name='layer3')\n","    x = make_layer(x, 512, blocks_per_layer[3], stride=3, name='layer4')\n","\n","    x = layers.Conv1D(filters=16, kernel_size=1, strides=1, use_bias=False, kernel_initializer=kaiming_normal, name='convdown')(x)\n","\n","\n","\n","    print(x.shape)\n","    for _ in range(rnn_n_layers):\n","        if rnn_type == 'gru':\n","            rnn_layer = layers.GRU(16, return_sequences=True)\n","        elif rnn_type == 'lstm':\n","            rnn_layer = layers.LSTM(16, return_sequences=True)\n","        elif rnn_type == 'simple':\n","            rnn_layer = layers.SimpleRNN(16, return_sequences=True)\n","        else:\n","            raise ValueError(\"rnn_type must be 'gru', 'lstm', or 'simple'\")\n","    if bidirectional:\n","        rnn_layer = layers.Bidirectional(rnn_layer)\n","\n","    x = rnn_layer(x)\n","    x = layers.GlobalAveragePooling1D(name='avgpool')(x)\n","    initializer = keras.initializers.RandomUniform(-1.0 / math.sqrt(512), 1.0 / math.sqrt(512))\n","    x = layers.Dense(units=num_classes, kernel_initializer=initializer, bias_initializer=initializer, name='fc')(x)\n","    x = layers.Activation('softmax')(x)\n","\n","\n","\n","    return x\n","\n","def resnet18(x, **kwargs):\n","    return resnet(x, [2, 2, 2, 2], rnn_n_layers=1,\n","                  rnn_type = 'simple', bidirectional= False, **kwargs)\n","\n","inputs = keras.Input(shape=(10000,))\n","# inputs = keras.Input(shape=(59953,))\n","outputs = resnet18(inputs, num_classes=NUM_CLASSES)\n","model = keras.Model(inputs, outputs)\n","\n"],"metadata":{"id":"Fc3y1Wp7gq8P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733258734846,"user_tz":480,"elapsed":303,"user":{"displayName":"Frank Wu","userId":"09777963439135390486"}},"outputId":"8181bc7a-7177-42d5-9cf4-53a5727a9e61"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["(None, 93, 16)\n"]}]},{"cell_type":"code","source":["import math\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","NUM_CLASSES = 8\n","\n","kaiming_normal = keras.initializers.VarianceScaling(scale=2.0, mode='fan_out', distribution='untruncated_normal')\n","\n","def conv3x3(x, out_planes, stride=1, name=None):\n","    x = layers.ZeroPadding1D(padding=1, name=f'{name}_pad')(x)\n","    return layers.Conv1D(filters=out_planes, kernel_size=3, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=name)(x)\n","\n","def basic_block(x, planes, stride=1, downsample=None, name=None):\n","    identity = x\n","\n","    out = conv3x3(x, planes, stride=stride, name=f'{name}.conv1')\n","    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn1')(out)\n","    out = layers.ReLU(name=f'{name}.relu1')(out)\n","\n","    out = conv3x3(out, planes, name=f'{name}.conv2')\n","    out = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.bn2')(out)\n","\n","    if downsample is not None:\n","        for layer in downsample:\n","            identity = layer(identity)\n","\n","    out = layers.Add(name=f'{name}.add')([identity, out])\n","    out = layers.ReLU(name=f'{name}.relu2')(out)\n","\n","    return out\n","\n","def make_layer(x, planes, blocks, stride=1, name=None):\n","    downsample = None\n","    inplanes = x.shape[2]\n","    if stride != 1 or inplanes != planes:\n","        downsample = [\n","            layers.Conv1D(filters=planes, kernel_size=1, strides=stride, use_bias=False, kernel_initializer=kaiming_normal, name=f'{name}.0.downsample.0'),\n","            layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name=f'{name}.0.downsample.1'),\n","        ]\n","\n","    x = basic_block(x, planes, stride, downsample, name=f'{name}.0')\n","    for i in range(1, blocks):\n","        x = basic_block(x, planes, name=f'{name}.{i}')\n","\n","    return x\n","\n","def resnet(x, blocks_per_layer, num_classes=1000):\n","    x = layers.Reshape((x.shape[-1], 1))(x)\n","    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn0')(x)\n","    # x = layers.ZeroPadding1D(padding=3, name='conv1_pad')(x)\n","    x = layers.Conv1D(filters=64, kernel_size=7, strides=2, use_bias=False, kernel_initializer=kaiming_normal, name='conv1')(x)\n","    x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5, name='bn1')(x)\n","    x = layers.ReLU(name='relu1')(x)\n","    # x = layers.ZeroPadding1D(padding=1, name='maxpool_pad')(x)\n","    x = layers.MaxPool1D(pool_size=3, strides=2, name='maxpool')(x)\n","\n","    x = make_layer(x, 64, blocks_per_layer[0], name='layer1')\n","    x = make_layer(x, 128, blocks_per_layer[1], stride=2, name='layer2')\n","    x = make_layer(x, 256, blocks_per_layer[2], stride=2, name='layer3')\n","    x = make_layer(x, 512, blocks_per_layer[3], stride=2, name='layer4')\n","    x = layers.Conv1D(filters=16, kernel_size=1, strides=1, use_bias=False, kernel_initializer=kaiming_normal, name='convdown')(x)\n","\n","\n","    rnn_layer = layers.SimpleRNN(16, return_sequences=True)\n","    x = rnn_layer(x)\n","\n","    x = layers.GlobalAveragePooling1D(name='avgpool')(x)\n","    initializer = keras.initializers.RandomUniform(-1.0 / math.sqrt(512), 1.0 / math.sqrt(512))\n","    x = layers.Dense(units=num_classes, kernel_initializer=initializer, bias_initializer=initializer, name='fc')(x)\n","    x = layers.Activation('softmax')(x)\n","\n","    return x\n","\n","def resnet18(x, **kwargs):\n","    return resnet(x, [2, 2, 2, 2], **kwargs)\n","\n","inputs = keras.Input(shape=(10000,))\n","# inputs = keras.Input(shape=(59953,))\n","outputs = resnet18(inputs, num_classes=NUM_CLASSES)\n","model = keras.Model(inputs, outputs)\n","\n"],"metadata":{"id":"F-5FajKHH35o","executionInfo":{"status":"ok","timestamp":1733259052154,"user_tz":480,"elapsed":327,"user":{"displayName":"Frank Wu","userId":"09777963439135390486"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g02vMCcfbKBD","executionInfo":{"status":"ok","timestamp":1733259056256,"user_tz":480,"elapsed":737,"user":{"displayName":"Frank Wu","userId":"09777963439135390486"}},"outputId":"cef473fb-925c-43cd-b7b8-45d6c336b4a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["6386\n","6386\n","800\n","800\n","Spectrogram shape: (128, 10000)\n","Label: (128, 8)\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","\n","\n","dataset_dir = \"data/raw_small/\"\n","\n","# Function to load a single .npy file and assign its label\n","def load_npy_file(file_path, label):\n","    # Read the file and decode its path\n","    npy = tf.numpy_function(lambda path: np.load(path).astype(np.float32), [file_path], tf.float32)\n","    npy.set_shape([10000,])  # Set shape (update according to your spectrogram's dimensions)\n","\n","    return npy, label\n","\n","\n","# Function to create a dataset for all files\n","def create_dataset(dataset_dir):\n","    # List all files and infer labels from folder names\n","    all_files = []\n","    all_labels = []\n","    for class_name in sorted(os.listdir(dataset_dir)):\n","        class_path = os.path.join(dataset_dir, class_name)\n","        if not os.path.isdir(class_path):\n","            continue\n","        label = ([int(digit) for digit in class_name])  # Convert folder name to integer label\n","        files = [os.path.join(class_path, f) for f in os.listdir(class_path) if f.endswith(\".npy\")]\n","        all_files.extend(files)\n","        all_labels.extend([label] * len(files))\n","\n","    print(len(all_labels))\n","    print(len(all_files))\n","\n","\n","\n","    # Create a dataset from the files and labels\n","    file_paths = tf.constant(all_files)\n","    labels = tf.constant(all_labels, dtype=tf.int32)\n","    num_classes = 8  # Determine the number of classes\n","    # labels = tf.one_hot(labels, depth=num_classes)  # Apply one-hot encoding\n","    # print(labels)\n","\n","    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n","    dataset = dataset.shuffle(len(all_files))  # Shuffle dataset\n","    dataset = dataset.map(load_npy_file, num_parallel_calls=tf.data.AUTOTUNE)  # Load files\n","    batch_size = 64\n","    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","    return dataset\n","\n","\n","# Create the train dataset\n","train_dataset = create_dataset(dataset_dir+\"train\")\n","val_dataset = create_dataset(dataset_dir+\"val\")\n","\n","\n","# Inspect a sample\n","for spectrogram, label in train_dataset.take(1):\n","    print(\"Spectrogram shape:\", spectrogram.shape)\n","    print(\"Label:\", label.shape)\n","    num_classes = label.shape[1]\n"]},{"cell_type":"code","source":["    from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","new_optimizer = keras.optimizers.Adam(learning_rate=0.0004)\n","model.compile(\n","    optimizer=new_optimizer ,\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","checkpoint = ModelCheckpoint(\n","    filepath='best_small_crnn_model.keras',  # Filepath to save the model\n","    monitor='val_accuracy',       # Metric to monitor (e.g., 'val_loss', 'val_accuracy')\n","    save_best_only=False,      # Save only the best model\n","    save_weights_only=False,  # Save the entire model (not just weights)\n","    mode='max',               # Save when the monitored metric decreases ('min') or increases ('max')\n","    verbose=1                 # Print a message when saving\n",")\n","\n","\n","\n","\n","history = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=40,\n","    verbose=1,\n","    callbacks=[checkpoint]\n","    # callbacks=[PrintEveryFewBatchesCallback(interval=1), checkpoint]\n",")\n","print('///////////////////////////////////')\n","print(history)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TctUxBoBj93t","outputId":"eb6b725f-db71-4094-88cb-36306fa3b2d7","executionInfo":{"status":"error","timestamp":1733260291233,"user_tz":480,"elapsed":864297,"user":{"displayName":"Frank Wu","userId":"09777963439135390486"}}},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661ms/step - accuracy: 0.2957 - loss: 1.9360\n","Epoch 1: val_accuracy improved from -inf to 0.29875, saving model to best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 790ms/step - accuracy: 0.2957 - loss: 1.9358 - val_accuracy: 0.2988 - val_loss: 1.9034\n","Epoch 2/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520ms/step - accuracy: 0.3020 - loss: 1.8860\n","Epoch 2: val_accuracy improved from 0.29875 to 0.31000, saving model to best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 589ms/step - accuracy: 0.3021 - loss: 1.8859 - val_accuracy: 0.3100 - val_loss: 1.8679\n","Epoch 3/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524ms/step - accuracy: 0.3135 - loss: 1.8547\n","Epoch 3: val_accuracy improved from 0.31000 to 0.33000, saving model to best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 594ms/step - accuracy: 0.3136 - loss: 1.8546 - val_accuracy: 0.3300 - val_loss: 1.8578\n","Epoch 4/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530ms/step - accuracy: 0.3401 - loss: 1.8153\n","Epoch 4: val_accuracy did not improve from 0.33000\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 635ms/step - accuracy: 0.3399 - loss: 1.8152 - val_accuracy: 0.3225 - val_loss: 1.8204\n","Epoch 5/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - accuracy: 0.3380 - loss: 1.7899\n","Epoch 5: val_accuracy improved from 0.33000 to 0.34250, saving model to best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 596ms/step - accuracy: 0.3381 - loss: 1.7897 - val_accuracy: 0.3425 - val_loss: 1.7922\n","Epoch 6/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - accuracy: 0.3595 - loss: 1.7635\n","Epoch 6: val_accuracy did not improve from 0.34250\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 590ms/step - accuracy: 0.3594 - loss: 1.7633 - val_accuracy: 0.3388 - val_loss: 1.7994\n","Epoch 7/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - accuracy: 0.3479 - loss: 1.7432\n","Epoch 7: val_accuracy improved from 0.34250 to 0.36125, saving model to best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 676ms/step - accuracy: 0.3482 - loss: 1.7430 - val_accuracy: 0.3613 - val_loss: 1.8028\n","Epoch 8/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550ms/step - accuracy: 0.3780 - loss: 1.6971\n","Epoch 8: val_accuracy did not improve from 0.36125\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 597ms/step - accuracy: 0.3780 - loss: 1.6971 - val_accuracy: 0.3587 - val_loss: 1.8041\n","Epoch 9/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - accuracy: 0.3916 - loss: 1.6670\n","Epoch 9: val_accuracy did not improve from 0.36125\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 587ms/step - accuracy: 0.3914 - loss: 1.6672 - val_accuracy: 0.3438 - val_loss: 1.7456\n","Epoch 10/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577ms/step - accuracy: 0.3768 - loss: 1.6612\n","Epoch 10: val_accuracy improved from 0.36125 to 0.36625, saving model to best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 632ms/step - accuracy: 0.3769 - loss: 1.6611 - val_accuracy: 0.3663 - val_loss: 1.7465\n","Epoch 11/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545ms/step - accuracy: 0.3929 - loss: 1.6238\n","Epoch 11: val_accuracy did not improve from 0.36625\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 592ms/step - accuracy: 0.3930 - loss: 1.6236 - val_accuracy: 0.3663 - val_loss: 1.7381\n","Epoch 12/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547ms/step - accuracy: 0.4170 - loss: 1.5758\n","Epoch 12: val_accuracy improved from 0.36625 to 0.37000, saving model to best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 608ms/step - accuracy: 0.4172 - loss: 1.5757 - val_accuracy: 0.3700 - val_loss: 1.7444\n","Epoch 13/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.4432 - loss: 1.5346\n","Epoch 13: val_accuracy improved from 0.37000 to 0.37500, saving model to best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 601ms/step - accuracy: 0.4431 - loss: 1.5346 - val_accuracy: 0.3750 - val_loss: 1.7511\n","Epoch 14/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - accuracy: 0.4516 - loss: 1.4911\n","Epoch 14: val_accuracy did not improve from 0.37500\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 592ms/step - accuracy: 0.4516 - loss: 1.4911 - val_accuracy: 0.3088 - val_loss: 1.8373\n","Epoch 15/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.4740 - loss: 1.4548\n","Epoch 15: val_accuracy did not improve from 0.37500\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 587ms/step - accuracy: 0.4741 - loss: 1.4547 - val_accuracy: 0.3750 - val_loss: 1.7448\n","Epoch 16/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - accuracy: 0.4948 - loss: 1.3744\n","Epoch 16: val_accuracy improved from 0.37500 to 0.38125, saving model to best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 609ms/step - accuracy: 0.4949 - loss: 1.3748 - val_accuracy: 0.3812 - val_loss: 1.7168\n","Epoch 17/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - accuracy: 0.5062 - loss: 1.3431\n","Epoch 17: val_accuracy did not improve from 0.38125\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 588ms/step - accuracy: 0.5064 - loss: 1.3430 - val_accuracy: 0.3525 - val_loss: 1.7578\n","Epoch 18/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.5385 - loss: 1.2679\n","Epoch 18: val_accuracy improved from 0.38125 to 0.41625, saving model to best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 602ms/step - accuracy: 0.5385 - loss: 1.2679 - val_accuracy: 0.4162 - val_loss: 1.6947\n","Epoch 19/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551ms/step - accuracy: 0.5737 - loss: 1.2000\n","Epoch 19: val_accuracy did not improve from 0.41625\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 604ms/step - accuracy: 0.5736 - loss: 1.2003 - val_accuracy: 0.3688 - val_loss: 1.7374\n","Epoch 20/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551ms/step - accuracy: 0.5825 - loss: 1.1625\n","Epoch 20: val_accuracy did not improve from 0.41625\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 611ms/step - accuracy: 0.5826 - loss: 1.1625 - val_accuracy: 0.3475 - val_loss: 1.7729\n","Epoch 21/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - accuracy: 0.5997 - loss: 1.1134\n","Epoch 21: val_accuracy did not improve from 0.41625\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 601ms/step - accuracy: 0.5999 - loss: 1.1132 - val_accuracy: 0.3938 - val_loss: 1.7208\n","Epoch 22/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543ms/step - accuracy: 0.6303 - loss: 1.0671\n","Epoch 22: val_accuracy did not improve from 0.41625\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 589ms/step - accuracy: 0.6303 - loss: 1.0670 - val_accuracy: 0.3825 - val_loss: 1.7123\n","Epoch 23/40\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-56fb6e7567ee>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["model = keras.models.load_model('final_models/best_small_crnn_model2.keras')\n","new_optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n","model.compile(\n","    optimizer=new_optimizer ,\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","checkpoint = ModelCheckpoint(\n","    filepath='final_models/crnn/best_small_crnn_model.keras',  # Filepath to save the model\n","    monitor='val_accuracy',       # Metric to monitor (e.g., 'val_loss', 'val_accuracy')\n","    save_best_only=False,      # Save only the best model\n","    save_weights_only=False,  # Save the entire model (not just weights)\n","    mode='max',               # Save when the monitored metric decreases ('min') or increases ('max')\n","    verbose=1                 # Print a message when saving\n",")\n","\n","\n","\n","\n","history = model.fit(\n","    train_dataset,\n","    validation_data=val_dataset,\n","    epochs=40,\n","    verbose=1,\n","    callbacks=[checkpoint]\n","    # callbacks=[PrintEveryFewBatchesCallback(interval=1), checkpoint]\n",")\n","print('///////////////////////////////////')\n","print(history)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":790},"id":"9i0pA108XkmO","executionInfo":{"status":"error","timestamp":1733261047300,"user_tz":480,"elapsed":299318,"user":{"displayName":"Frank Wu","userId":"09777963439135390486"}},"outputId":"5a5c1797-a436-4a0e-f3ec-9b6588738b1d"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698ms/step - accuracy: 0.5646 - loss: 1.2152\n","Epoch 1: saving model to final_models/crnn/best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 800ms/step - accuracy: 0.5648 - loss: 1.2149 - val_accuracy: 0.4087 - val_loss: 1.6819\n","Epoch 2/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522ms/step - accuracy: 0.5769 - loss: 1.1719\n","Epoch 2: saving model to final_models/crnn/best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 592ms/step - accuracy: 0.5771 - loss: 1.1718 - val_accuracy: 0.4013 - val_loss: 1.6790\n","Epoch 3/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - accuracy: 0.5901 - loss: 1.1521\n","Epoch 3: saving model to final_models/crnn/best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 581ms/step - accuracy: 0.5902 - loss: 1.1522 - val_accuracy: 0.3988 - val_loss: 1.6779\n","Epoch 4/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step - accuracy: 0.6006 - loss: 1.1431\n","Epoch 4: saving model to final_models/crnn/best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 584ms/step - accuracy: 0.6006 - loss: 1.1432 - val_accuracy: 0.4013 - val_loss: 1.6737\n","Epoch 5/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - accuracy: 0.6083 - loss: 1.1291\n","Epoch 5: saving model to final_models/crnn/best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 591ms/step - accuracy: 0.6081 - loss: 1.1293 - val_accuracy: 0.4000 - val_loss: 1.6731\n","Epoch 6/40\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536ms/step - accuracy: 0.6081 - loss: 1.1395\n","Epoch 6: saving model to final_models/crnn/best_small_crnn_model.keras\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 597ms/step - accuracy: 0.6080 - loss: 1.1393 - val_accuracy: 0.3988 - val_loss: 1.6743\n","Epoch 7/40\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-47f25dcfb156>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"whMOmE2VXiI_"},"execution_count":null,"outputs":[]}]}